
import sys
import argparse
import os
import json
from pathlib import Path
from datetime import datetime

import logging
logging.getLogger("scapy.runtime").setLevel(logging.ERROR)
from scapy.all import *

import pandas as pd

cwd = os.getcwd()
sys.path.insert(1, cwd + '/src')
import PcapUtils
import MUDGenUtils
from Analyses import *
from Constants import *
from VMUDEnforcer import Virtual_MUD_enforcer
from MRTACharacterizator import MRTACharacterizator
from MRTAPairClustersProcessor import MRTAPairClustersProcessor
import device_mrt_pcaps_to_csv as mrttocsv


"""
	MUD Resources :) @:
		- NIST https://www.nccoe.nist.gov/projects/building-blocks/mitigating-iot-based-ddos/securing-home-iot-devices   
		- NIST https://github.com/usnistgov/MUD-PD 
		- https://github.com/iot-onboarding/mud-visualizer
		NOTE: MUD resources and interest have increased a whole lot since February 2021!
		- NIST https://www.nccoe.nist.gov/content/mud-related-resources
"""


""" Project TODO's
	
	- TODO: (adj 26/7/21)
			* Compact pcap-to-csv bidir flows tool, to have it scale on whatever pcap>CSV to feed MRTA
		* DONE - Code MRTA module taking logic from colab file morgese-master-thesis-main.ipynb (https://colab.research.google.com/drive/1tLYoY6I0XJq5vSUoMhRG-UuT0J8HVe9a?usp=sharing)

	- TODO: (adj 27/7/21)
			* Flexibilize CSV/Dataframe column names as Constant values (e.g., [TS, TE, SA] instead of ['ts', 'te', 'sa', ...])

	- TODO: (adj 28/7/21)
			* Validate HDBSCAN parameters with AMI-precision over different batches of various dimensions, report average for selected params.
			* Implement eventualities-robust OpenFlow rules generation from MUD profile, not to rely on MUDGee
			* INVESTIGATE MUD-PD https://github.com/usnistgov/MUD-PD (installed in ~/Software, import pcaps crashes as of now...)

	- TODO TODO TODO (adj 23/9/21)
			* Flexibilize CSV generation from single pcaps in a folder.
	
	- TODO TODO TODO TODO (adj 14/10/21)
		* INSTEAD OF FILTERING PACKETS AND MATCHING AGAINST FLOWS, FIRST CONVERT PCAP TO FILTER INTO FLOWS, AND THEN FILTER IT
		* In other words, switch the pcaps-to-flows-csv procedure one step eariler, and directly output MRT Flow CSVs



Chair Andrea Continella
Committee member: Roland and Andreas
External: Roland
Other: Thijs, Tim


0031 534893250 Sanne

"""




def main(arguments=None):


	################################################################################################
	# Arguments definition
	################################################################################################

	parser = argparse.ArgumentParser(description='TBD')

	# Mode can be "mudgen", "reject", "analyze"
	modes_list = [MODE_MUDGEN, MODE_REJECT, MODE_FLOWS_GENERATION, MODE_ANALYZE]
	parser.add_argument('--mode', metavar='<mode of program execution>',
						help=f"One of: [ {modes_list} ] .\n Consult documentation on github for detailed usage explanation!",
						required=True)

	# If mode is "mudgen", a MUD config file to feed MUDgee is needed
	parser.add_argument('--mudgen_config', metavar='<JSON file for mudgee MUD generation>', help='name of JSON file for mudgee MUD generation', required=False)

	# If mode is "reject", 
	#   - the config file for the referred device and gateway information, and
	#   - the relative path to MUD (OpenFLow) rules in CSV
	# must be specified
	parser.add_argument('--reject_config', metavar='<JSON file of MUD config for filtering data>', help='name of MUD config JSON for specified MUD to enforce.\nRequired if mode is "reject"', required=False)
	parser.add_argument('--reject_mud_rules', metavar='<Relative-path of CSV file of filtering rules (only OpenFlow standard supported ATM)>', help='CSV rules file generated by MUDgee, for specific device MUD to enforce.\nRequired if mode is "reject"', required=False)
	parser.add_argument('--reject_to_named_dir', metavar='<String>', help='Name of directory that will be generated in outputs/<device>/ where the results of the "reject" operation will be stored.\nThis parameter is optional', required=False)

	# Not udsed at the moment
	parser.add_argument('--reject_online_interface', metavar='<String>', help='Name of the local interface on which to listen to device traffic."', required=False)

	# Optional, if set, limits the number of packets that are processed when rejecting traffic
	parser.add_argument('--pcap_limit', metavar='<integer>', help='Number to indicate how many packets will be processed by either functionality', required=False)

	# Generation of custom NetFlow CSV file
	parser.add_argument('--flowsgen_tgt_dir', metavar='<String>', help='Full or relative path to directory containing MUD-rejected pcap files', required=False)


	analysis_actions_list = [ANALYSIS_ACTION_IPS_FLOWS_GRAPHS, ANALYSIS_ACTION_PORTS_FLOWS_GRAPHS, ANALYSIS_ACTION_PKTS_CSV, ANALYSIS_ACTION_IPS_MAP, ANALYSIS_ACTION_FILTER_KNOWN_PROVIDERS, ANALYSIS_ACTION_MRTA_CHARACTERIZE, ANALYSIS_ACTION_DEVICE_MRT_EVOLUTION_DATAGEN]
	parser.add_argument('--analysis_action', metavar='<string to perform>', help='Indicates what action to perform in analysis, related to analysis pcap.\nSupported actions are \n{}.'.format(analysis_actions_list), required=False)

	parser.add_argument('--analysis_tgt', metavar='<pcap/csv file path>', help='path to file containing MRT-related information. Consult documentation for exhaustive explanation.', required=False)
	parser.add_argument('--analysis_capture_metadata', metavar='<file path to json object/dict>', help='Metadata dictionary object describing the capture to analyse. \nIt shall contain at least "device_id" (string), and "deployment_info" (any type as of now) that describes the setting where the device is (e.g., lon, lat, industry_type, ...)', required=False)
	parser.add_argument('--analysis_devname', metavar='<name of device>', help='name of the device to which the filtering refers. It is needed to output the analysis results to the right folder [outputs/<devname>].', required=False)
	
	parser.add_argument('--dsr_path', help='Dataset Scaler Reference path. Must be specified to set global scaling parameters when processing MRT flows, for --analysisi_action={}'.format(ANALYSIS_ACTION_MRTA_CHARACTERIZE), required=False)

	################################################################################################
	# Arguments parsing
	################################################################################################

	args = parser.parse_args(arguments)

	mode = args.mode

	# NOTE: All parameters default to None values if not specified

	# mudgen_config specifies gateway MAC, IPv4, IPv6; device MAC, name; PCAP file on which device MUD is generated
	mudgen_config = MUD_CONFIGS_FOLDER + args.mudgen_config if args.mudgen_config is not None else None

	# relative path to define, allows use of filtering rules from other origins than MUDgee
	reject_config = args.reject_config if args.reject_config is not None else None
	reject_mud_rules = args.reject_mud_rules if args.reject_mud_rules is not None else None
	pcap_limit = int(args.pcap_limit) if (args.pcap_limit is not None and int(args.pcap_limit) > 0) else None
	reject_to_named_dir = args.reject_to_named_dir if args.reject_to_named_dir is not None else None
	reject_online_interface = args.reject_online_interface if args.reject_online_interface is not None else None

	flowsgen_tgt_dir = args.flowsgen_tgt_dir if args.flowsgen_tgt_dir is not None else None

	analysis_action = args.analysis_action if args.analysis_action is not None else None
	analysis_capture_metadata = CHATACTERIZATION_METADATA_FOLDER + args.analysis_capture_metadata if args.analysis_capture_metadata is not None else None
	analysis_tgt = args.analysis_tgt if args.analysis_tgt is not None else None
	analysis_devname = args.analysis_devname if args.analysis_devname is not None else None
	
	dsr_path = args.dsr_path if args.dsr_path is not None else None

	################################################################################################
	# Preliminary files existence checks
	################################################################################################

	# Manage case if files do not exist
	if mudgen_config is not None and not os.path.isfile(mudgen_config):
		print('>>> ERROR: Mudgen config [ {} ] does not exist'.format(mudgen_config), file=sys.stderr)
		sys.exit(-1)
	if reject_config is not None and not (os.path.isfile(reject_config) or os.path.isdir(reject_config)):
		print('>>> ERROR: Reject config [ {} ] does not exist'.format(reject_config), file=sys.stderr)
		sys.exit(-1)
	if analysis_capture_metadata is not None and not os.path.isfile(analysis_capture_metadata):
		print('>>> ERROR: Analysis characterization metadata [ {} ] does not exist'.format(analysis_capture_metadata), file=sys.stderr)
		sys.exit(-1)
	if reject_mud_rules is not None and not os.path.isfile(reject_mud_rules):
		print('>>> ERROR: Mud filtering rules [ {} ] does not exist'.format(reject_mud_rules), file=sys.stderr)
		sys.exit(-1)
	if analysis_tgt is not None and not (os.path.isfile(analysis_tgt) or os.path.isdir(analysis_tgt)):
		print('>>> ERROR: File/directory to analyse [ {} ] does not exist'.format(analysis_tgt), file=sys.stderr)
		sys.exit(-1)
	if dsr_path is not None and not os.path.isfile(dsr_path):
		print('>>> ERROR: Dataset scaler reference does not exist at [ {} ]'.format(dsr_path), file=sys.stderr)
		sys.exit(-1)

	# NOTE: Modes in if-elif-else as mutually exclusive
	################################################################################################
	# MODE MUDGEN
	################################################################################################

	# Create MUD config file to feed MUDgee
	if mode == MODE_MUDGEN:
		if mudgen_config is not None:
			# Get info from MUD config file
			print('>>> MUDGEN CONFIG FILE: {}'.format(mudgen_config))
			with open(mudgen_config) as mg_cf:
				mg_data = json.load(mg_cf)
			device_name = mg_data['deviceConfig']['deviceName']
			# Run mudgee
			mudgee_gen_outcome = MUDGenUtils.run_mudgee(mudgen_config)
			print('>>> MUD data to generate with MUDgee from info in config file {}'.format(mudgen_config)) 
		else:
			# Get info from MUD config file
			print('>>> MUDGEN CONFIG FILE: {}'.format(MUD_DEFAULT_CONFIG_FILE))
			with open(MUD_DEFAULT_CONFIG_FILE) as mg_cf:
				mg_data = json.load(mg_cf)
			device_name = mg_data['deviceConfig']['deviceName']
			# Run mudgee
			mudgee_gen_outcome = MUDGenUtils.run_mudgee(MUD_DEFAULT_CONFIG_FILE)
			print('>>> MUD config file not provided for "mudgen". Defaulting on {}'.format(MUD_DEFAULT_CONFIG_FILE))

		if mudgee_gen_outcome == 0:
			print('>>> MUD data output in result/{}'.format(device_name))
		else:
			print('>>> Some error occurred in generating MUD data.')


	################################################################################################
	# MODE REJECT
	################################################################################################

	elif mode == MODE_REJECT:
		# Check all parameters entered
		if  reject_mud_rules is None:
			print('>>> Parameter missing: --reject_mud_rules.')
			sys.exit(-1)
		# Check if MUD rules exist
		if not os.path.isfile(reject_mud_rules):
			print('>>> MUD-derived (OpenFlow) rules CSV file <{}> not found.'.format(reject_mud_rules))
			sys.exit(-1)
		if reject_config is None and reject_online_interface is None:
			print('>>> Filtering modality not specified. Provide either of the parameters: --reject_config, --reject_online_interface')
			sys.exit(-1)

		# Get useful data
		if reject_config is not None: # RUN IN PCAP
			if os.path.isfile(reject_config):
				with open(reject_config) as mc_data:
					data = json.load(mc_data)
				dev_name = data['deviceConfig']['deviceName'] 
				dev_mac = data['deviceConfig']['device']
				gw_mac = data['defaultGatewayConfig']['macAddress']
				reject_pcap = data['filterPcapLocation']

				# Check if pcap to process exists
				if reject_pcap is not None and not os.path.isfile(reject_pcap):
					print('>>> "{}" does not exist. Check --reject_config file key-values {} \n>>> (if null: are you trying to use a MUDgee config file?) '.format(reject_pcap, json.dumps(data, indent=4)), file=sys.stderr)
					sys.exit(-1)

				v_mud_enf = Virtual_MUD_enforcer(dev_mac, dev_name, gw_mac, reject_mud_rules)
				# Run virtual MUD enforcer on pcap, for given
				v_mud_enf.enforce_in_pcap(reject_pcap, pcap_limit, save_json=True, named_dir=reject_to_named_dir)

			# If --reject_config parameter is a directory, iterate over all pcaps in directory and filter according to other parameters
			elif os.path.isdir(reject_config):
				
				config_folder_base = os.path.basename(os.path.normpath(reject_config))
				print('>>> IN-CONFIG FOLDER: {}'.format(config_folder_base))
				
				tgt_dir = os.fsencode(reject_config)
				for file in os.listdir(tgt_dir):
					filename = os.fsdecode(file)
					if filename.endswith('.json'):
						
						reject_config = os.fsdecode(tgt_dir) + '/' + filename

						print('>>>>>>>>>>>>>>>>>')
						print('######################## Filtering from config: \n{}'.format(reject_config))
						print('>>>>>>>>>>>>>>>>>')

						if os.path.isfile(reject_config):
							with open(reject_config) as mc_data:
								data = json.load(mc_data)
							dev_name = data['deviceConfig']['deviceName'] 
							dev_mac = data['deviceConfig']['device']
							gw_mac = data['defaultGatewayConfig']['macAddress']
							reject_pcap = data['filterPcapLocation']

							# Check if pcap to process exists
							if reject_pcap is not None and not os.path.isfile(reject_pcap):
								print('>>> "{}" does not exist. Check --reject_config file key-values {} \n>>> (if null: are you trying to use a MUDgee config file?) '.format(reject_pcap, json.dumps(data, indent=4)), file=sys.stderr)
								sys.exit(-1)

							v_mud_enf = Virtual_MUD_enforcer(dev_mac, dev_name, gw_mac, reject_mud_rules)
							# Run virtual MUD enforcer on pcap, for given
							v_mud_enf.enforce_in_pcap(reject_pcap, pcap_limit, named_dir=reject_to_named_dir)

						
						print('<<<<<<<<<<<<<<<<<')
						print('######################## Done filtering from config: \n{}'.format(reject_config))
						print('<<<<<<<<<<<<<<<<<')

			else:
				print('>>> Parameter --reject_config does not seem to be a file nor directory. Specify a valid path.\n>>> Parameter given: {}'.format(reject_config))
				sys.exit(-1)

		if reject_online_interface is not None: # RUN ONLINE LOCALLY
			print('>>> Attempt listening on interface [ {} ] to filter traffic as specified by rules at [ {} ]'.format(reject_online_interface, reject_mud_rules))
			# Local variable to my mac
			dev_mac = '3c:22:fb:97:59:a1'
			dev_name = 'macbook-local-test'
			gw_mac = '88:36:6c:d7:1c:56'
			v_mud_enf = Virtual_MUD_enforcer(dev_mac, dev_name, gw_mac, reject_mud_rules)
			v_mud_enf.enforce_online(reject_online_interface)

		# ONLINE MODE NOTES
		"""
		- Listen on determined interface
		- Listen for MAC-specific (device-specific) packets
		- As a MUD enforcer, it should DROP>STORE non-mud packets, and forward MUD packets
		- As a MUD listener, it should just collect the already-filtered packets
		"""


	################################################################################################
	# MODE FLOWS FILE GEN
	################################################################################################

	elif mode == MODE_FLOWS_GENERATION:
		if flowsgen_tgt_dir is None or not os.path.isdir(flowsgen_tgt_dir):
			raise ValueError(f">>> ERROR: Null or invalid --flowsgen_tgt_dir argument for mode {MODE_FLOWS_GENERATION}. Please enter a valid path to folder containing pcaps to convert to flows CSV file. Exiting.")

		mrttocsv.module_each_pcap_to_complete_csv(flowsgen_tgt_dir)


	################################################################################################
	# MODE ANALYZE
	################################################################################################

	elif mode == MODE_ANALYZE:

		if analysis_tgt is None or analysis_devname is None:
			print('>>> Make sure to provide path to pcap/csv/directory to analyse, via the parameter --analysis_tgt\n>>> Also please specify device name with parameter --analysis_devname, needed to reference output folder for analysis actions.')
			sys.exit(-1)
		
		output_folder = OUTPUTS_FOLDER + analysis_devname + '/'

		"""
		NOTE: Discontinued
		if analysis_action == ANALYSIS_ACTION_PKTS_CSV:
			csv_gen_res = PcapUtils.get_pcap_csv(analysis_tgt, analysis_devname)
			if csv_gen_res != -1:
				print('>>> {} has been generated. Please analyse it on Kibana'.format(csv_gen_res))
			else:
				print('>>> An error occurred trying to generate CSV from pcap file {}'.format(analysis_tgt))
				sys.exit(-1)
		if analysis_action == ANALYSIS_ACTION_IPS_FLOWS_GRAPHS:
			# Analyses functions
			display_flows_ips_description_info_graph(analysis_tgt)
		if analysis_action == ANALYSIS_ACTION_PORTS_FLOWS_GRAPHS:
			display_flows_ports_description_info_graph(analysis_tgt)
		if analysis_action == ANALYSIS_ACTION_IPS_MAP:
			folium_map(analysis_tgt, analysis_devname)
		if analysis_action == ANALYSIS_ACTION_FILTER_KNOWN_PROVIDERS:
			ti_register = TIRegister(analysis_tgt, analysis_devname)
			ti_register.filter_out_known_backends_pkts_from_pcap()
		"""
		############################################################################### MRTA CHARACTERIZE
		if analysis_action == ANALYSIS_ACTION_MRTA_CHARACTERIZE:
			###### Checks
			if analysis_capture_metadata is None:
				raise ValueError('>>> ERROR: analysis_capture_metadata parameter unspecified. Exiting'.format(mode))
			if dsr_path is None:
				raise ValueError('>>> ERROR: Dataset Scaler_generator Reference is unspecified. Exiting'.format(mode))

			metadata = {}
			try:
				with open(analysis_capture_metadata) as md:
					metadata = json.load(md)
			except Exception as e:
				print(e)
				print('>>> Unable to get analysis capture metadata. A JSON-consistency issue?')
				sys.exit(-1)
			if metadata['device_id'] is None or metadata['deployment_info'] is None:
				print('>>> device_id or deployment_info entries missing in analysis_capture_metadata [ {} ]. Exiting.'.format(analysis_capture_metadata))
				sys.exit(-1)

			##### Operations
			if os.path.isdir(analysis_tgt):
				dir = os.fsencode(analysis_tgt)
				for data in os.listdir(dir):
					data_name = os.fsdecode(data)
					if data_name.endswith(CSV_CLEAN_LABEL): # RUNS ON ALL PER-PCAP CSVs, OUTPUTS CORRESPONDING AMOUNT OF CHARACTERIZATION FILES

						path_to_file = analysis_tgt + '/' + data_name

						mrta_characterizator = MRTACharacterizator(metadata, path_to_file, dsr_path)
						mrta_characterizator.input_to_characterization_data()

						# Output name, default or specified
						now = datetime.now()
						dt_string = now.strftime("%Y%m%d_%H-%M-%S")
						characterization_name = 'ch_' + dt_string + '_' + analysis_devname + data_name + '.json'

						output_path = output_folder + analysis_devname + '_mrt_characterizations/'
						Path(output_path).mkdir(parents=True, exist_ok=True)
						mrta_characterizator.save_characterization(output_path + characterization_name)
			else:
				mrta_characterizator = MRTACharacterizator(metadata, analysis_tgt, dsr_path)
				mrta_characterizator.input_to_characterization_data()

				# Output name, default or specified
				now = datetime.now()
				dt_string = now.strftime("%Y%m%d_%H-%M-%S")
				characterization_name = 'ch_' + dt_string + '_' + analysis_devname + os.path.splitext(analysis_tgt)[0] + '.json'

				output_path = output_folder + analysis_devname + '_mrt_characterizations/'
				Path(output_path).mkdir(parents=True, exist_ok=True)
				mrta_characterizator.save_characterization(output_path + characterization_name)


		############################################################################### MRT EVOLUTION DATAGEN

		# Given array of characterization file paths, compute two-by-two sequences of transition characterization, and output (produced dataset) to specific folder
		if analysis_action == ANALYSIS_ACTION_DEVICE_MRT_EVOLUTION_DATAGEN:

			if not os.path.isdir(analysis_tgt):
				raise ValueError(f">>> ERROR: In order to run action [ {ANALYSIS_ACTION_DEVICE_MRT_EVOLUTION_DATAGEN} ] --analysis_tgt must be a directory, containing characterization files for a specific device. Exiting.")
			analysis_tgt = os.path.abspath(analysis_tgt)

			"""
			*****************************************************************************************************
        	* TODO: Move to deticated class/file function
        	*****************************************************************************************************
			"""
			# Order files chronologically wrt start date of each characterization, to be then analyzed two-by-two
			ordered_characterizations = {}
			tgt_dir = os.fsencode(analysis_tgt)
			for file in os.listdir(tgt_dir):
				filename = os.fsdecode(file)
				filename = os.fsdecode(tgt_dir) + filename if os.fsdecode(tgt_dir).endswith('/') else os.fsdecode(tgt_dir) + '/' + filename
				if filename.endswith('.json'):
					with open(filename, 'r') as file:
						try:
							f = json.load(file)
							start_timestamp = f['metadata']['time_window'][0]
						except KeyError as e:
							raise ValueError(f">>> ERROR: Unable to fetch time information from characterization file {filename}. Is the JSON format valid?. Exiting.")

					start_timestamp = float(datetime.timestamp(datetime.strptime(start_timestamp, STRFTIME_READABLE_FORMAT)))
					ordered_characterizations[filename] = start_timestamp
			
			ordered_characterizations = dict(sorted(ordered_characterizations.items(), key=lambda item: item[1]))
			#print(ordered_characterizations)
			
			"""
				FEDLAB
				NOTE : LEGIT ORDER : chrono_ch_files = [k for k in ordered_characterizations.keys()]

				NOTE - CURRENTLY TESTING WITH ALPHABETICAL ORDER : `same attacks' scenario
					[k for k in sorted(ordered_characterizations.keys(), key=lambda s:s.rsplit('_')[-1])]
				NOTE - CURRENTLY TESTING WITH SHUFFLED ORDER : `different attacks' scenario
					[k for k in random.sample(ordered_characterizations.keys(), len(ordered_characterizations.keys()))]
			"""
			chrono_ch_files = [k for k in ordered_characterizations.keys()]
			#chrono_ch_files = [k for k in random.sample(ordered_characterizations.keys(), len(ordered_characterizations.keys()))]
			for f in chrono_ch_files:
				print(f)
			
			#print(chrono_ch_files)
			# Produce two-by-two MRT clusters transition data entries
			entries_list = []
			
			for ch1, ch2 in zip(chrono_ch_files, chrono_ch_files[1:]):
				mrta_pcp = MRTAPairClustersProcessor(ch1, ch2)
				mrta_pcp.populate_clusters_shifts_data()
				mrta_pcp.set_transition_characterization_data()

				transition_df = mrta_pcp.get_transition_characterization_data_df_entry()
				mrta_pcp.print_distance_matrix(readable_only=False)
				entries_list.append(transition_df)
			
			df = pd.concat(entries_list, ignore_index=True)
			#print('CREATED DATASET')
			#print(df)

			now = datetime.now()
			dt_string = now.strftime("%Y%m%d_%H-%M-%S")
			clusters_evol_df_name = 'clusters_evols_' + dt_string + '_' + analysis_devname + '.csv'

			output_path = output_folder + analysis_devname + '_mrt_transitions_dfs/'
			Path(output_path).mkdir(parents=True, exist_ok=True)
			df.to_csv(output_path + clusters_evol_df_name)
			

	else:
		print('>>> --mode argument "{}" is invalid. Exiting.'.format(mode))
		sys.exit(-1)

"""
python run.py --mode analyze --analysis_tgt ./outputs/ieee-ezviz-complete/mirai-httpflooding-all-ezviz-rejected.json --analysis_action ips_flows_graphs --analysis_devname ieee-ezviz
"""


if __name__ == '__main__':
	main()
	sys.exit(0)

"""
	Full Pipeline sample: ('+' are preferred usage)
	
	1 > python run.py
		--mode mudgen 
		--mudgen_config config.json (located in configs/mudgen_config/ directory)

	NOTE: run-ezviz-tests.py can extend rejected pcap generation to folder of pcaps to reject traffic from!
		--rules_arg
		--tgt_folder

	2 > python run.py
		--mode reject 
		--reject_config config.json (located in configs/reject_config/ directory)
		--reject_mud_rules mudgee/out/devicefolder/*rule.csv --pcap_limit int (OPTIONAL)

	3 > python device_mrt_pcaps_to_csv.py --pcaps_dir outputs/device_name/

	4 > python run.py
		--mode analyze 
		--analysis_action one-of-Constants.py{ANALYSIS_ACTION_*}
			+ ANALYSIS_ACTION_MRTA_CHARACTERIZE : mrta_characterize
		--analysis_devname devicename_used_in_configs_above 
		--analysys_file 
			+ path/to/rejectedflowsCSV.csv (in NetFlow format and as parsed via device_mrt_pcaps_to_csv)
			OR
			path/to/pcapwithrejectedpackets.pcap
		--analysis_capture_metadata capture_metadata.json (located in configs/characterization_datas/ directory)




**** DEMO COMMANDS FOR SINGLE-DEVICE FUNCTIONS ****

# Generate MUD profile
$> python3 run.py --mode mudgen --mudgen_config ieee-ezviz-demo-1.json

# Filter traffic off a pcap
$> python3 run.py --mode reject --reject_mud_rules result/ieee-ezviz-demo-1/ieee-ezviz-demo-1rule.csv --reject_config configs/reject_configs/ieee-ezviz-demo-1-A-floods --reject_to_named_dir time_1
$> python3 run.py --mode reject --reject_mud_rules result/ieee-ezviz-demo-1/ieee-ezviz-demo-1rule.csv --reject_config configs/reject_configs/ieee-ezviz-demo-1-B-scans --reject_to_named_dir time_2

# Generate NetFlow CSV
$> python3 run.py --mode flows_gen --flowsgen_tgt_dir outputs/ieee-ezviz-demo-1/ieee-ezviz-demo-1_time_1
$> python3 run.py --mode flows_gen --flowsgen_tgt_dir outputs/ieee-ezviz-demo-1/ieee-ezviz-demo-1_time_2

# Cluster flows in CSV and generate characterization file
$> python3 run.py --mode analyze --analysis_devname ieee-ezviz-demo-1 --analysis_action mrta_characterize --analysis_capture_metadata characterization_test.json --analysis_tgt outputs/ieee-ezviz-demo-1/ieee-ezviz-demo-1_time_1/ieee-ezviz-demo-1_time_1-all-flows-csv/*-CLN.csv 
[ieee-ezviz-demo-1_time_1-all-flows-gen-custom-format-CLN.csv]
$> python3 run.py --mode analyze --analysis_devname ieee-ezviz-demo-1 --analysis_action mrta_characterize --analysis_capture_metadata characterization_test.json --analysis_tgt outputs/ieee-ezviz-demo-1/ieee-ezviz-demo-1_time_2/ieee-ezviz-demo-1_time_2-all-flows-csv/*-CLN.csv 
[ieee-ezviz-demo-1_time_2-all-flows-gen-custom-format-CLN.csv]

# Generate the traffic evolution dataframe based on sequential pairwise traffic characterization files
$> python3 run.py --mode analyze --analysis_devname ieee-ezviz-demo-1 --analysis_action device_mrt_evolution_datagen --analysis_tgt outputs/ieee-ezviz-demo-1/ieee-ezviz-demo-1_mrt_characterizations



**** MACROs reject traffic to characterization file ****

python3 MACRO_rjt_to_ch.py --devname ieee-ezviz-demo-1 --reject_config configs/reject_configs/ieee-ezviz-demo-1-A-mirai-floods --reject_to_named_dir time_1 --flowsgen_tgt_dir outputs/ieee-ezviz-demo-1/ieee-ezviz-demo-1_time_1 --analysis_capture_metadata characterization_test.json

python3 MACRO_rjt_to_ch.py --devname ieee-ezviz-demo-1 --reject_config configs/reject_configs/ieee-ezviz-demo-1-B-scans --reject_to_named_dir time_2 --flowsgen_tgt_dir outputs/ieee-ezviz-demo-1/ieee-ezviz-demo-1_time_2 --analysis_capture_metadata characterization_test.json

"""


"""
#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*
# 			TODO - CHANGE TO CSV-PER-PCAP APPROACH!!!!!!!!
#			DONE >>> IT LOOKS LIKE IT WORKS!!
#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*


DSR PATH EZVIZ: '/Users/lucamrgs/Big_Data/IEEE-Huy-Kang/dataset_scaler_gen_reference.csv'

$> python3 run.py --mode mudgen --mudgen_config <file>.json

$> python3 src/generate_rjt_configs.py --tgt_dir <full path to dir with pcaps to reject from> --devname <devname> --dev_mac <dev mac> --gw_mac <> --gw_ip4 <> [--gw_ip6 <>]

$> python3 run.py --mode reject --reject_mud_rules result/<device-id>/<device-id>rule.csv --reject_config path/to/<name of generated rjt folder>

$> python3 run.py --mode flows_gen --flowsgen_tgt_dir outputs/<device-id>[/rjt pcaps folder]

$> python3 run.py --mode analyze --analysis_devname <device-id> --analysis_action mrta_characterize --dsr_path <path to dataset scaling generation reference csv> --analysis_capture_metadata <metadata-filename>.json --analysis_tgt outputs/<device-id>/<flows CSV folder>

$> python3 run.py --mode analyze --analysis_devname <device-id> --analysis_action device_mrt_evolution_datagen --analysis_tgt outputs/<device-id>/<mrt characterizations folder>

"""

